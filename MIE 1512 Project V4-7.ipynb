{"cells":[{"cell_type":"code","source":["def add_zero(s):\n\n    if len(s) < 2:\n\n        return \"0\" + s\n\n    else:\n\n        return s"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["import urllib\ndef downloadNDays(y, m, d, duration):\n    for i in range(duration):\n        Y= add_zero(str(y))\n        M= add_zero(str(m))\n        D= add_zero(str(d))\n        for i in range(24):\n            urllib.urlretrieve((\"http://data.githubarchive.org/%s-%s-%s-%s.json.gz\" %(Y, M, D, i)), (\"/tmp/%s-%s-%s-%s.json.gz\" %(Y, M, D, i)))\n        d= d+1\n## define the download functions to get data from github archive"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["downloadNDays(2017,3,2,1)\n## download the data from 2017-3-1 to 2017-3-3"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["%fs\nls file:/tmp/"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["PATH_PREFIX= \"/tmp/\"\nEXT_JG=\".json.gz\"\nEXT_JSON= \".json\"\n\ndef get_file_name_json_gz(para_list):\n\n    return get_file_name(para_list) + EXT_JG\n\ndef get_file_name_json(para_list):\n\n    return get_file_name(para_list) + EXT_JSON\n\ndef get_file_name(para_list):\n\n    list_ = list(map(str,para_list))\n\n    list_[1] = add_zero(list_[1])    \n\n    list_[2] = add_zero(list_[2])\n\n    return '-'.join(list_)\n\n    \n"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["import gzip\ndef merge_one_day(cy, cm, cd):\n\n   tmp = []\n\n   for hh in range(24):\n\n       with gzip.open(PATH_PREFIX + get_file_name_json_gz([cy, cm, cd, hh]), 'r') as f_in:\n\n           tmp += f_in\n\n\n   with open(PATH_PREFIX + get_file_name_json([cy, cm, cd, 0]), 'wb') as f_out:\n\n       for line in tmp:\n\n           f_out.write(line)\n\n"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["merge_one_day(2017,3,2)\n## decompress the data and put these json files into one json"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["import shutil\nwith open('/tmp/2017-03-01-0.json', 'rb') as f_in:\n  with gzip.open('/tmp/2017-03-01.json.gz', 'w') as f_out:\n    shutil.copyfileobj(f_in,f_out)\n    "],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["\ndbutils.fs.mv(\"file:/tmp/2017-03-01-0.json\", \"dbfs:/FileStore/tables/gh_archive/2017-01-05-0.json\")"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["%fs\nls file:/tmp/"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["from pyspark.sql.types import *\n\ninputPath = \"file:/tmp/2017-03-02-0.json\"\n\n\nInputDF = sqlContext.read.json(inputPath)\n\nInputDF.show()\n# read the json file into a spark dataframe"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["from pyspark.sql import functions\ngithubInput = InputDF.withColumn(\"actorID\", InputDF.actor.id)\ngithubInput = githubInput.withColumn(\"actorName\", InputDF.actor.login)\ngithubInput = githubInput.withColumn(\"repoId\", InputDF.repo.id)\ngithubInput = githubInput.withColumn(\"repoName\", InputDF.repo.Name)"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["githubInputDF= githubInput.select(\"id\",\"type\",\"actorID\",\"actorName\",\"repoID\",\"repoName\",\"created_at\")"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["from pyspark.sql.functions import count\ngithubGroupDF= githubInputDF.groupBy(['actorID','actorName','type']).agg(count(\"id\").alias(\"_count\"))"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["githubGroupDF.take(5)"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["typeList= githubGroupDF.select('type').distinct().rdd.map(lambda r: r[0]).collect() ## without actorID"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["typeList2= [str(x) for x in typeList]"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["type_list= []\ntype_list.extend(['actorID'])\ntype_list.extend(typeList2)\n"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["type_list ## with actorID"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["githubGroupedData= githubGroupDF.groupBy(['actorID','actorName']).pivot('type', typeList ).sum(\"_count\")\n## get the number of events for each user in 2017-3-1"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":["githubGroupedData.show()"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":["githubRdd = githubGroupedData.select(typeList).filter(\"PushEvent<100\").na.fill(0).rdd"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"code","source":["from pyspark.mllib.stat import Statistics\nsummary = Statistics.colStats(githubRdd.map(list))\nprint(summary.mean())  # a dense vector containing the mean value for each column\nprint(summary.variance())  # column-wise variance\nprint(summary.numNonzeros())  # number of nonzeros in each column\n# get the statistics of the data"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":["githubRdd2= githubGroupedData.select(type_list).filter(\"PushEvent<100\").na.fill(0).rdd"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"code","source":["githubRdd2.toDF().createOrReplaceTempView('github')"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"code","source":["%sql\nselect * from github"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"code","source":["from pyspark.sql.functions import *\nfrom pyspark.mllib.clustering import KMeans, KMeansModel\nclusters = KMeans.train(githubRdd.map(list), 3, maxIterations=15, initializationMode=\"k-means||\" )\n\n# feed the data into the kmeans model"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"code","source":["clusters.centers"],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"code","source":["clusterLabel= clusters.predict(githubRdd.map(list))\n## get the cluster of each user"],"metadata":{},"outputs":[],"execution_count":29},{"cell_type":"code","source":["index= sc.parallelize(clusterLabel.collect())\nz= index.zip(sc.parallelize(githubRdd2.map(list).collect()))"],"metadata":{},"outputs":[],"execution_count":30},{"cell_type":"code","source":["z.take(5)"],"metadata":{},"outputs":[],"execution_count":31},{"cell_type":"code","source":["new_rdd= z.map(lambda (x,y): [x, y[0], y[1], y[2], y[3], y[4], y[5], y[6], y[7], y[8], y[9], y[10], y[11], y[12], y[13], y[14]])"],"metadata":{},"outputs":[],"execution_count":32},{"cell_type":"code","source":["type_list2= []\ntype_list2.extend(['clusters'])\ntype_list2.extend(type_list)\nnew_df= new_rdd.toDF(type_list2)"],"metadata":{},"outputs":[],"execution_count":33},{"cell_type":"code","source":["new_df.show()"],"metadata":{},"outputs":[],"execution_count":34},{"cell_type":"code","source":["new_df.createOrReplaceTempView('githubCluster')"],"metadata":{},"outputs":[],"execution_count":35},{"cell_type":"code","source":["%sql\nselect clusters, avg(PushEvent) push, avg(GollumEvent) Gollum, avg(ReleaseEvent) Release, avg(CommitCommentEvent) Commit, avg(CreateEvent) create_, avg(PullRequestReviewCommentEvent) PullRequestComment, avg(IssueCommentEvent) IssueComment, avg(DeleteEvent) Delete, avg(IssuesEvent) Issue, avg(ForkEvent) Fork, avg(PublicEvent) Public, avg(MemberEvent) Member, avg(WatchEvent) Watch, avg(PullRequestEvent) PullRequest from githubCluster\ngroup by \nclusters\n/* plot the average number of actions for each clusters */"],"metadata":{},"outputs":[],"execution_count":36},{"cell_type":"code","source":["from math import sqrt\n\ndef error(point): \n    center = clusters.centers[clusters.predict(point)] \n    return sqrt(sum([x**2 for x in (point - center)]))\n\nWSSSE = (githubRdd.map(lambda point:error(point)).reduce(lambda x, y: x+y))\nprint('Within Set Sum of Squared Error = ' + str(WSSSE))\n# define the cost function for each kmeans model."],"metadata":{},"outputs":[],"execution_count":37},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":38},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":39},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":40}],"metadata":{"name":"MIE 1512 Project","notebookId":824919656181841},"nbformat":4,"nbformat_minor":0}
